\documentclass[12pt,a4paper,parskip,listof=totoc,bibliography=totoc]{scrreprt}
\usepackage[english,german,ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
%http://www.namsu.de/Extra/pakete/Setspace.html
\usepackage{setspace}
%Fußnoten werden das ganze Dokument über durchgezählt
%Quelle: http://golatex.de/nummerierung-der-fussnoten-durchgehend-im-gesamten-dokument-t2042.html
\usepackage{chngcntr}
\counterwithout{footnote}{chapter}
\usepackage{makeidx}
\makeindex
\usepackage{graphicx}
%Für Quellcodeschnippsel
%Für Bash Code Highlighting
\usepackage{minted}
%Anleitung: https://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings
\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=bash,                 % the language of the code
  otherkeywords={*,...},           % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}
%head statt top bringt exakt 4cm Abstand am Kopf
\usepackage[left=4.00cm, right=2.00cm, head=4.00cm, bottom=2.00cm]{geometry}
%Glossar anschalten und in TOC aufnehmen und erzeugen
%https://en.wikibooks.org/wiki/LaTeX/Glossary
\usepackage{hyperref} %Klickbare Einträge im Glossar
%\usepackage[toc,acronym]{glossaries}
%\makeglossaries
%\usepackage[nomain,acronym,xindy,toc]{glossaries} % nomain, if you define glossaries in a file, and you use \include{INP-00-glossary}
%http://tex.stackexchange.com/questions/111192/problems-with-xindy-and-glossaries
%\usepackage[nonumberlist,nomain,acronym,toc]{glossaries}
% Acronym muss an erster Stelle stehen, sonst funktioniert die Trennung von Abkürzungsverzeichnis und Glossar nicht
\usepackage[acronym,nonumberlist,toc]{glossaries}
\input{seminararbeit_monitoring_glossar}
\input{seminararbeit_monitoring_acronyme}
\makeglossaries
%\usepackage{imakeidx}
%Tiefe der Nummerierung ändern, Subsubsection ist Ebene 3
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{4}
% Bibliothek & Zitierstil
\usepackage[style=authortitle-icomp,backend=biber]{biblatex}
\usepackage[babel,german=guillemets]{csquotes}
%\bibliography{seminararbeit_monitoring.bib} %U.u. deprecated
% Anleitung zu BibLaTEX: http://biblatex.dominik-wassenhoven.de/download/DTK-2_2008-biblatex-Teil1.pdf
\addbibresource{seminararbeit_monitoring.bib}
%So werden URLs im Literaturverzeichnis in eine neue Zeile geschrieben
%Quelle: http://www.golatex.de/biblatex-literaturverzeichnis-zeilenumbruch-vor-url-t8406.html
\DeclareFieldFormat{url}{\newline URL: \url{#1} }
\setuptoc{toc}{bibliography=totoc}
% Abkürzungsverzeichnis mit Nomencl
% siehe http://texwelt.de/wissen/fragen/4942/wie-kann-ich-die-erstellung-eines-abkurzungsverzeichnisses-mit-dem-paket-nomencl-automatisieren
% und http://golatex.de/abkuerzungsverzeichnis-mit-texmaker-t8301.html
% Zum aktualisieren muss "Makeindex" aufgerufen werden, Konfiguration siehe letzter Link
%\usepackage[intoc]{nomencl}
% Befehl umbenennen in abk
%\let\abk\nomenclature
% Überschrift
%\renewcommand{\nomname}{Abkürzungsverzeichnis}
% Punkte zw. Abkürzung und Erklärung
%\setlength{\nomlabelwidth}{.20\hsize}
%\renewcommand{\nomlabel}[1]{#1 \dotfill}
% Zeilenabstände verkleinern
%\setlength{\nomitemsep}{-\parsep}
%\makenomenclature
% Ende Abkürzungsverzeichnis

%\usepackage{showframe}% zum Anzeigen des Seitenlayouts

%% Abstände um Chapter
%\RedeclareSectionCommand[beforeskip=-1\baselineskip,afterskip=.5\baselineskip]{chapter}

%\pagestyle{headings}
%Schriftgrößen noch ein wenig anpassen...
\setkomafont{chapter}{\fontsize{16bp}{18.8bp}\selectfont}
\setkomafont{section}{\fontsize{14bp}{18.8bp}\selectfont}
%\addtokomafont{disposition}{\hspace*{1.5cm}}
\renewcommand{\chapterheadstartvskip}{\vspace*{-1\topskip}}
\renewcommand{\chapterheadendvskip}{\vspace*{0.2\topskip}}
\renewcommand*{\chapterheadstartvskip}{\vspace*{-\topskip}}

\begin{document}
	%TODO: Titelseite an die Erfordernisse anpassen
	%http://golatex.de/wiki/Widmung
	\subject{Seminararbeit im Studiengang \glqq Verwaltungsinformatik\grqq}
	\author{Markus Österle\\ Matrikelnr.: 20131041}
	\title{Servermonitoring im Rechenzentrum}
	\subtitle{am Beispiel von Linux Systemen}
	\publishers{Betreut von Dipl. Inf. Stefan Müller}
	\date{} % setzt ein leeres Datum und löscht quasi das per default verwendete \today von der Titelseite

	\maketitle
	
	\tableofcontents
	% Gibt das Latex Logo aus...Stelle? 
	%\LaTeXe{}
	%Ab hier 1.5facher Zeilenabstand 
	\onehalfspacing
	\chapter{Einleitung}
	Das Thema des Servermonitorings hat sich im professionellen \acrshort{it} Umfeld in den letzten Jahren zu einem großen Thema entwickelt. Durch die steigende Abhängigkeit nahezu aller Bereiche unseres Lebens von \acrshort{it}-Systemen steigen auch die Anforderungen an die Verfügbarkeit und die Performance und somit auch an die Überwachung der selbigen. Reichte es in den 90er Jahren noch aus von einem zentralen Rechner (gemeint ist hier ein normaler Personal Computer) per Ping zu überwachen ob die Server verfügbar sind, so wird heute ein sehr viel feineres Monitoring erwartet. Nicht nur die Erreichbarkeit der Rechner soll überwacht und statistisch aufbereitet werden, sondern auch die Auslastung und die Gesundheit einzelner Bauteile (bspw. \acrlong{psu}s (Netzteile), \acrshort{ram} Bausteine; \acrshort{cpu}, Festplatten), soll lückenlos überwacht werden. Um eine schnelle Reaktion auf eventuell auftretende Fehler zu ermöglichen. 

	In der vorliegenden Arbeit wird das Thema \glqq Servermonitoring im Rechenzentrum\grqq\ betrachtet. Zur Begrenzung des Themengebiets wird dezidiert ausführlicher auf das Teilgebiet der Überwachung von Linux-Systemen eingegangen. Dies hat zum einen den Grund, dass der Autor viele Jahre Erfahrung mit Linux und Unix Betriebssystemen vorweisen kann und schon einige Erfahrung mit der Überwachung von Linux-Servern gemacht hat und zum anderen ermöglicht diese Eingrenzung eine tiefergehende Beschäftigung mit wenigstens einem Themengebiet.
	\section{Warum Monitoring im Rechenzentrum?}
	%TODO kritische Betriebszustände definieren?
	Aus der Sicht eines Systemadministrators (in Folge nur noch Admin genannt) macht es eigentlich von Grunde auf Sinn so viele Informationen wie nur möglich über seine Systeme zu haben:
	\begin{itemize}
		\item Wie sind meine Server ausgelastet?
		\item Ist die Hardware in Ordnung?
		\item War der gestrige Ansturm auf die Homepage zu verkraften?
		\item Zeigen meine Server ungewöhnliches Verhalten?
		\item Ist meine Sicherheitssoftware up to date?
	\end{itemize}
	  All diese Fragen könnten über ein richtig eingesetztes und konfiguriertes Monitoringsystem schnell und sicher beantwortet werden. Darüber hinaus ermöglicht ein solches System dem Admin schnell auf kritische Betriebszustände (\acrlong{bspw} Netzteil im Server oder Festplatte im RAID ausgefallen) zu reagieren und diese zu beheben, was sich positiv bei der Ausfallzeit seiner Systeme bemerkbar macht. 
	  
	  Ein ebenfalls positiver Nebeneffekt ist, dass ein gutes Monitoring den Admin in die Lage versetzt schnell (grafisch) aufbereitetes Material zur Verfügung stellen zu können, mit dem man zum Beispiel nachweisen kann, dass die Systeme dringend aufgerüstet werden müssen oder das Performanceprobleme manchmal eben doch an schlecht programmierter Software und nicht an den Systemen liegt.
	  
	\section{Warum Linux?}
	Systemüberwachung ist natürlich für alle Komponenten im Rechenzentrum wichtig, begonnen bei der Basisversorgung (Strom, Kühlung) über die grundlegende Infrastruktur (Netzwerkinfrastruktur, evtl. Storageinfrastruktur) bis zu den einzelnen Systemen (natürlich quer über die Betriebssystemgrenzen hinweg). Mit den später in dieser Arbeit vorgestellten Lösungen könnten viele dieser Felder abgedeckt werden, eine genaue Beschreibung des wie würde allerdings den (sowohl den zeitlichen als auch den mengenmäßigen) Rahmen der Arbeit sprengen, wie bereits in der Einleitung erwähnt. 
	
	Deshalb werden wir uns nach den allgemeinen Definitionen und Einführungen in den Themenkomplex \glqq Monitoring\grqq\ auf das Thema der Serverüberwachung von Linux Systemen spezialisieren. Dies ist ein relativ dankbares Gebiet für diese Ausführungen da man relativ gut die Mächtigkeit und Schlagkraft eines richtig konfigurierten Monitoringsystems zeigen kann. Für Linux spricht auch, dass es zum einen eine relativ große Verbreitung im Serverbereich hat und die Arbeit auch für den privaten Gebrauch nicht irrelevant ist, da der Überwachung mit den vorgestellten Tools keine Grenzen gesetzt sind durch den modularen Aufbau und die Erweiterbarkeit mit selbstgeschriebenen Skripten, Plugins, \acrshort{etc}. sind der Phantasie keine Grenzen gesetzt. Die Systeme können beispielsweise ohne großen Aufwand (Anleitungen und Code für vieles gibt es im Netz) für die Überwachung privater Webservices, privater Netzwerkinfrastrukturen, SmartHomes, Wetterstationen, \acrshort{etc} genutzt werden.
		
	
	\chapter{Vom Ping zum proaktiven Monitoring}
	In den folgenden Unterkapiteln werde ich mich mit der grundlegenden Definition von Begriffen rund um das Thema Monitoring/Serverüberwachung beschäftigen und einen kleinen Überblick über die Historie geben.
	\section{Historie}
	Zu Beginn der IT Zeit, als Server noch Mainframes und sehr teuer waren und wenige spezialisierte Anwendungen auf ihnen betrieben wurden, war die Überwachung dieser Systeme für die Administratoren ein kleiner Aufwand. Die Administratoren waren über ihre Terminals meistens sowieso direkt mit dem Mainframe verbunden und sahen (in der bedienten Betriebszeit) etwaige Fehlermeldungen sofort auf ihren Konsolen. Darüber hinaus kam es sehr oft auch darauf an, das die Software lief, wie spielte oftmals eine eher untergeordnete Rolle. Dies hat sich im Wandel der Zeit drastisch verändert, die großen Mainframes von einst werden durch eine Vielzahl von kleineren Servern ersetzt um die gestiegenen Anforderungen erfüllen zu können. Wo früher auf einem Rechner (mit der entsprechenden Hot-/Cold-Standby-Lösung wenn die Firma/Behörde) die Datenbanken für die komplette Firma liefen, werden diese heute durch eine Vielzahl an Datenbanksystemen (die unter Umständen auch noch Hochverfügbar ausgelegt sind) ersetzt. Dies und die Tatsache, dass ohne diese IT Systeme in vielen Bereichen nicht mehr funktioniert führt natürlich auch zu ganz anderen Anforderungen an Verfügbarkeit und damit auch an die Erkennung von Fehlern und Ausfällen. 
	
	Während es früher ausreichend war, mit einer selbst gestrickten (Skript-)Lösung per \textit{Ping} zu überwachen ob alle Server erreichbar sind und bei einem Fehler der Admin sich selbst in den Serverraum gehen musste um den Rechner und seine Fehlermeldung in Augenschein zu nehmen muss es heute etwas detaillierter sein. Zumindest die Anwendungen die für den Betrieb kritisch sind müssen überwacht werden um Fehler und Ausfälle schnell erkennen und beheben zu können, unter Umständen möchte man auch einfach bei Ausfall einer Anwendung eine automatische Aktion auslösen (z.B. einen automatischen Neustart des Webservers). Auch die Fehlermeldung soll nach Möglichkeit bereits im Monitoring erkennbar sein.
	
	Das (lokale) Monitoring von Performanceparametern war in der Geschichte der *nix Betriebssysteme schon immer möglich, der Komfort und die Zahl der Tools hat sich über die Jahre gesteigert. Tools wie \textit{top} haben ihren Ursprung in den 80er Jahren\footcite{top} (lauffähig unter Unix), also sogar vor der Entwicklung von Linux (ab 1991). Das Sysstat Paket mit Tools wie \textit{iostat} für das Monitoring der Festplattenaktivität und \textit{SAR} für fortlaufendes Schreiben von Performance Daten per Cronjob gibt es seit 06.03.1999\footcite{sysstatchangelog}.
	%TODO Wo wollen wir hier hin?
	Cacti und RRDTool
	Systemlogs die in ihrer Vielzahl unüberblickbar sind und um Sie überhaupt verarbeiten zu können auf jeden Fall gefiltert und aufbereitet werden müssen. Verschiedene Logserver (Syslog-ng, rsyslog, systemd).
	
	Auch eine zunehmende Standardisierung der IT Prozesse wie beispielsweise \acrfull{itil} und die damit verbundenen Pflichten zur Messung bestimmter Größen tragen ihren Teil zur Notwendigkeit von immer umfangreicheren Monitoring- und Reportingsystemen bei. Auf \acrshort{itil} gehen wir im folgenden Kapitel noch einmal ausführlicher ein.
	%\subsection{ITIL die Quelle allen Übels?}
	%Definition ITIL - ITIL \& Monitoring?
	%\acrfull{itil}
	
	\section{Definitionen rund um das Thema (Server-/System-)Monitoring}
	Was verbirgt sich nun hinter magischen Begriffen wie \acrshort{itil} und Monitoring, in der Folge werde ich versuchen die gebräuchlichsten Definitionen darzulegen und zu beschreiben wie die einzelnen Spielarten des Monitorings mittels Tools im praktischen Teil der Arbeit umgesetzt werden.
	\subsection{ITIL}
	Die Begrifflichkeit \acrshort{itil} wird uns in der Folge noch öfter über den Weg laufen. Ausgeschrieben heißt \acrshort{itil}: \acrlong{itil} und ist eine über Jahrzehnte gewachsene Sammlung von Best Practices zum Thema IT Service Management\footcite{ebelitilv3}. \glqq\acrfull{itsm} nutzt Methoden, die nötig sind, um die bestmögliche Unterstützung von Geschäftsprozessen durch die IT-Organisation zu erreichen. \acrshort{itil} ist der diesbezüglich genannte De-facto-Standard\grqq\footcite[S. 27]{ebelitilv3}, was aber nicht gleichzusetzen ist mit einem offiziellen Standard. 
	Services was ist das? Unter Service versteht man bei \acrshort{itil} die Gesamtheit der physischen und logischen (IT- und nicht IT-) Komponenten, die benötigt werden, um die Unterstützung ausgewählter Geschäftsprozesse sicherzustellen.\footcite{sommeritservicemgmt}
	Alles dreht sich darum Qualität des IT Services zu verbessern.
	
	%https://de.wikipedia.org/wiki/ITIL_V3_Service_Operation
	ITIL Service Operation? 
	
	Für eine vernünftige Einführung von \acrshort{itil} im Unternehmen ist ein funktionierendes Monitoring- und Reportingsystem unbedingt notwendig.
	\subsection{Monitoring - Allgemein}
	%TODO Definition Monitoring
	Laut dem Duden handelt sich beim Monitoring um
	\begin{center}
		\glqq[Dauer]beobachtung (eines bestehenden Systems)\grqq\footcite[S. 701; Stichwort Monitoring]{duden}
	\end{center}
	Dieser Definition ist auch aus Informatikersicht nicht mehr allzu viel hinzuzufügen, außer dass es sich natürlich in unserem Fall um die Beobachtung eines \acrshort{it}-Systems handelt. Unter diese Definition fällt sowohl die temporäre Beobachtung, wie sie \acrlong{bspw} mit \textit{top} realisiert werden kann als auch eine dauerhafte Beobachtung bei der gesammelte (Performance-)Daten von einzelnen Rechner per Skript, Agent oder ähnlichem an ein zentrales System übertragen werden, wo sie gespeichert und ausgewertet werden.
	
	\subsection{reaktives Monitoring}
	\glqq Reaktives Monitoring ist eine Form der Überwachung, bei der als Reaktion auf ein bestimmtes Event entsprechende Maßnahmen eingeleitet werden. Beispielsweise die Auslösung eines Batchjobs, sobald ein vorheriger Batchjob abgeschlossen wurde, oder die Erfassung eines Incidents, wenn ein Fehler auftritt\grqq
	\footcite[S. 511]{ebelitilv3}
	
	Die Begrifflichkeit des Incidents kommt aus der \acrshort{itil}-Welt und bezeichnet die Eröffnung eines Fehlertickets in einem Ticketsystem und die Weiterleitung des selbigen an die zuständige Stelle, wenn eine Störung auftritt. Die Auslösung eines Batchjobs ist in Nagios zwar möglich, aber normalerweise wird man für die Zwecke der Arbeits-/Auftragsverwaltung (auch Job Steuerung genannt) speziellere Systeme verwenden. Was allerdings möglich ist, ist \acrlong{bspw} bei Systemen bei denen kein Datenverlust (zumindest wenn man abgebrochene Sitzungen der Benutzer außen vor lässt) droht einen automatischen Neustart durchzuführen sobald diese Abstürzen oder ungewöhnliches Verhalten zeigen, mit einer solchen Vorgehensweise könnten u.U. Benachrichtigungen von teuren Rufbereitschaftskräften abgesehen werden.
	 
	\subsection{proaktives Monitoring}
	%http://www.thefreedictionary.com/proactive
	\glqq Proaktives Monitoring ist eine Form der Überwachung, bei der versucht wird, Event-Muster zu ermitteln, um mögliche zukünftige Ausfälle zu prognostizieren.\grqq \footcite[S. 511]{ebelitilv3}
	
	Nach meiner Auffassung stellt ein richtiges proaktives Monitoring die Königsdisziplin innerhalb des Monitorings dar. Zwar hat sich die (Überwachungs-)Software und die Vielzahl der verfügbaren Agenten (siehe spätere Kapitel) in den letzten Jahren stark verbessert und die dadurch gestiegene Vielzahl an verfügbaren Informationen erleichtert einiges. Aber es Bedarf immer noch einer kundigen Hand, die die jeweiligen Filter definiert, damit das System beim überschreiten kritischer Werte Alarm schlägt. \footcite{Borkmann2009}
	
	Um ein vernünftiges proaktives Monitoring realisieren zu können brauche ich für die Analyse immer die größtmögliche Anzahl an Informationen, eine breitere Datenbasis erleichtert die Einschätzung des Fehlers. Deshalb halte ich es in diesem Fall für richtig und wichtig, nicht nur Performancedaten und Daten über den Status der einzelnen Anwendungen zu sammeln und auszuwerten, sondern auch die System- und Anwendungslogs nach kritischen Mustern zu durchsuchen und ggf. Alarm zu schlagen.
	%TODO Mustererkennung vor Ausfall, Borkmann einbauen
	\subsection{Verfügbarkeitsmonitoring}
	Verfügbarkeitsmonitoring bezeichnet die Überwachung der Verfügbarkeit, einer Anwendung oder eines Servers, d.h. die Beantwortung der Frage \glqq Wie lange war der Server/die Anwendung für den Kunden erreichbar\grqq\. Das Monitoring der Verfügbarkeit kann ein Teil des SLA-Monitorings sein, wenn im SLA eine spezifische Verfügbarkeit vereinbart wurde, darauf gehen wir im nächsten Abschnitt noch näher ein, wenn wir uns mit dem Thema SLA-Monitoring noch näher beschäftigen.
	\subsection{SLA Monitoring}
	Unter einem \acrfull{sla} versteht man in ITIL eine \glqq Vereinbarung zwischen einem \acrshort{it} Service Provider und einem Kunden, der einen zu erbringenden Service und dessen Service Level inklusive Service Level-Zielen, Verantwortlichkeiten von \acrshort{it} Service Provider und Kunde genau definiert. Ein \acrshort{sla} kann mehrere IT Services oder Kunden abdecken.\grqq \footcite[S. 732; Stichwort: Service Level Agreement]{ebelitilv3} Die im \acrshort{sla} vereinbarten Service Level-Ziele sollten SMART sein und auf KPIs basieren, d.h. mess- und überprüfbar sein.\footcite[S. 733; Stichwort: Service Level-Ziele]{ebelitilv3}
	
	Beim SLA Monitoring geht es darum die Einhaltung der vereinbarten Service Level-Ziele zu überwachen und sinnvoller Weise in Form von Reportings für die Kunden und die Kollegen vom Service Level Management (die Stelle die lt. \acrshort{itil} für die Verhandlung und Vereinbarung des \acrshort{sla} zuständig ist) aufzubereiten und zur Verfügung zu stellen.
	%TODO Fußnote noch an den Text nach oben ziehen.
	Einhaltung vereinbarter Servicelevel \footcite[40]{iso20000sla}
	\subsection{Fazit}
	%TODO ITIL Begrifflichkeit vs. technische Begrifflichkeit, also proaktiv, reaktiv, SLA vs. Basis, erweitertes, spezialisiertes Monitoring
	Um alle in den vergangenen Unterkapiteln beschriebenen Anforderungen zu erfüllen ist es notwendig mehrere Überwachungstechnologien zu verbinden, um ein optimales Monitoring zu erhalten. So ist es zur proaktiven Erkennung von Fehlern zum einen unerlässlich die Einträge in Logfiles auswerten zu können, um Fehler zu bemerken lange bevor Sie beginnen sich auf den Produktivbetrieb auszuwirken (bspw. Schreibfehler auf ein per \acrlong{fc} (\acrshort{fc}) angebundenes \acrshort{san}-System oder einfach I/O Fehler auf eine der Systemfestplatten) und zum anderen auch die Performance der Systeme im Auge zu behalten um sicher zu stellen, dass die Dimensionierung der Systeme richtig ist und nicht plötzliche Engpässe auftreten können. Dies ist vor allem durch die grafische Aufbereitung und historische Speicherung der Daten möglich. 
	\chapter{Monitoring Systeme für Linux Server}

	Nachdem wir im vorherigen Kapitel einige grundlegende Begriffe bereits geklärt haben, ist es nun an der Zeit uns Gedanken darüber zu machen, wie ein Monitoring aussehen könnte und was es alles leisten sollte. 
	\section{Grundlegende Überlegungen}
	Die wesentlichen Fragen\footcite[nach][]{veltnagios1} vor Beginn einer Implementierung einer Monitoring Lösung sollten sein:
	\begin{itemize}
		\item Was soll überwacht werden?
		\item Wie kann überwacht werden?
		\item Wer soll im Fehlerfall benachrichtigt werden?
		\item Welche Service Level Agreements existieren bereits, welche sollen in naher Zukunft abgeschlossen werden?
		\item Welche Software ist für meine Zwecke am besten geeignet?
	\end{itemize}
	\subsection{Was soll überwacht werden?}
	Hier kann man die Themenbereiche grob in drei Stufen der Überwachung einteilen, die drei Stufen gruppieren die Anforderungen entsprechend dem Aufwand
	\begin{itemize}
		\item Grundlegende Überwachung
		
		Stufe mit dem wenigsten Aufwand, hier wird im wesentlichen kontrolliert ob alle Server und Serverdienste erreichbar sind und ob die Netzwerkinfrastruktur in Ordnung ist.\\
		\textbf{Mit TCP/IP realisierbar}
		\item Erweiterte Überwachung
		
		Beispielsweise Auslastung von Routern \& Switchports oder Auslastung von Servern, freier Platz auf Festplatten, Datenbanken\\
		\textbf{Mit Hilfe von speziellen Protokollen, z.B. \acrshort{snmp} oder applikationsbezogenen Werkzeugen realisierbar}
		\item Spezialisierte Überwachung
		
		Temperaturüberwachung der \acrshort{dv}-Räume, Qualität der Stromversorgung, aktuelle Netzlast der einzelnen Serverräume\\
		\textbf{Nur mit individueller Hard- und Software realisierbar (Beispielsweise Überwachungsmodule in den Schaltschränken und Sensorik in den Rechnerräumen )}
	\end{itemize}
	\subsection{Wie kann überwacht werden?}
	Im wesentlichen können an dieser Stelle zwei Arten der Überwachung unterschieden werden:
	\begin{itemize}
		\item Aktive Überwachung
		\begin{itemize}
		\item In regelmäßigen Abständen werden Programme ausgeführt, die eine Überprüfung durchführen
		\item Die Rückgabewerte werden ausgewertet
		\item Besteht ein Fehler über längere Zeit (bzw. über einen definierten Zeitraum hinaus) wird ein Zuständiger informiert
		\end{itemize}
		\item Passive Überwachung
		\begin{itemize}
			\item Ein Dienst, Server, Agent, o.ä. meldet einen Fehler
			\item Die Eingabe wird ausgewertet
			\item Je nach Ereignis und Konfiguration wird ein Zuständiger informiert
		\end{itemize}
	\end{itemize}
	\subsection{Wer soll im Fehlerfall benachrichtigt werden?}
	Diese Frage ist in den meisten (größeren) Unternehmen und Behörden gar nicht so einfach zu beantworten, da die Aufgabengebiete unterteilt sind und es unter Umständen schwierig ist die passende Person zu informieren, da die (technische) Abbildung von Zuständigkeiten an vielen Stellen kompliziert bis nicht möglich ist. 
	
	Weiter stellt sich das Problem das nicht bei jedem Ausfall die gleichen Personen zu benachrichtigen sind:
	So kann es sich beim Ausfall eines Servers um vielfältige Probleme handeln, \acrlong{bspw} ein Betriebssystem- oder ein Netzwerkproblem.
	Außerdem muss festgelegt werden ob und wer 24/7 (also 24h am Tag, sieben Tage die Woche) über aufgetretene Fehler informiert werden muss/soll.
	\subsection{Welche Service Level Agreements existieren bereits, welche sollen in naher Zukunft abgeschlossen werden?}
	Diese Information ist besonders wichtig um festlegen zu können welche Kennzahlen ich auf jedem Fall aus meinem Monitoring bekommen will um den Anforderungen gerecht zu werden.
	\subsection{Welche Software ist für meine Zwecke am besten geeignet?}
	Bei der Recherche nach Monitoringtools für Linux Systeme stößt man auf verschiedenste Lösungen, da wären zum einen die Lösungen die lokal auf jedem Server zu installieren sind, der Performance Monitor \textit{top} und seine Derivate (atop, iotop, htop, ntop) oder das Systat-Paket\footcite{sysstat} mit seinen Komponenten (\acrlong{bspw} SAR\footcite{sarkrenn}, iostat). Allerdings haben alle diese Programme das Problem, dass ich mich auf dem Server anmelden muss um Informationen zu bekommen, einzig bei SAR hätte ich die Möglichkeit, die per Cronjob generierten Dateien per Skript einzusammeln und auf einem zentralen Server mit einem Tool wie KSar\footcite{ksar} grafisch auszuwerten oder KSar die Daten selbst einsammeln zu lassen indem ich mich auf dem Server anmelde wenn ich Performance Daten brauche. Dies ist allerdings nicht wirklich befriedigend da es bei diesen Lösungen um ein reines Monitoring von Performancedaten geht und nicht um ein Monitoring der Verfügbarkeit bestimmter Dienste oder die Benachrichtigung/Alarmierung im Fehlerfall. Um eine solche Funktionalität zu erhalten brauchen wir ein zentrales System. 
	%TODO Quelle für die per Cronjob generierten Dateien?
	Wenn man zu dem Thema \glqq zentrales Monitoringsystem für Linux\grqq\ im Internet recherchiert wird man neben den diversen teuren Softwarelösungen diverser Hersteller (z.B. \acrlong{ca} Unified Monitoring oder Microsoft SCOM) immer wieder über einen Namen stolpern: Nagios. Das Tool hat sich fürs Monitoring von Linux Systemen zu einer Art Industrie Standard entwickelt. Das mag zum einen an seiner freien Verfügbarkeit liegen, zum anderen aber vielleicht auch daran, dass im Linux Umfeld viele Administratoren die Quelloffenheit und die leichte Erweiterbarkeit mittels eigener Tools, Plugins, Agenten von Nagios schätzen. Darüber hinaus findet man ein weites Angebot an Support und Serviceleistungen, sowohl im Internet, als auch von Consultingfirmen, die meist auch an der Entwicklung der Systeme beteiligt sind. Und wahrscheinlich der gewichtigste Vorteil gegenüber allen Mitbewerbern, eine Nagios Installation kostet erstmal nichts, ich brauche lediglich einen Server auf dem ich die Software installieren kann und einen Administrator der gewillt ist sich in die Konfiguration einzuarbeiten. 
	
	Die eigentlich schon sehr gut und ausgereifte Architektur von Nagios auf der einen Seite und die immer wieder auftretenden Querelen bei der Entwicklung von Nagios, haben zu einer Vielzahl an Forks (als Fork bezeichnet man in der Softwareentwicklung eine Aufspaltung eines Projekts in zwei unterschiedliche voneinander unabhängige Projekte, die voneinander unabhängig weiterentwickelt werden) geführt. 
	Einige dieser Forks sind:
	\begin{itemize}
		\item \textbf{Icinga} 
		
		Entstanden 2009 aus Frust über die schleppende Weiterentwicklung von Nagios als Fork\footcite{icingaabspaltung}, Version 2 wurde von Grund auf neu entwickelt (\glqq from scratch\grqq), die Software soll aber so lange wie möglich kompatibel zu Nagios bleiben.\footcite{icingafaq}
		\item \textbf{Shinken}
		
		vollständige Portierung von Nagios in die Programmiersprache Python, Umstellung von Original Nagios auf Shinken sind ohne großen Aufwand möglich, da sowohl die Plugins, als auch die Konfigurationsdateien weiterhin funktionieren \footcite{shinkenabout}
		\item \textbf{Naemon}
	\end{itemize} gesorgt. Für die weitere Arbeit, gehen wir davon aus, dass die Auswahl in die Richtung Nagios gefallen ist, im nächsten Kapitel werden wir uns damit beschäftigen welche Möglichkeiten wir haben und welchen Funktionsumfang uns Nagios bietet.
	
	
	\section{Performance \& SLA Monitoring}
	%TODO: Warum Check_MK, warum nicht OMD, Vielfalt der Systeme OMD, Check_MK, OMD Lab Edition, bei ursprünglicher OMD auf der Seite nichts passiert, hinter den Kulissen aber schon, warum empfiehlt es sich trotzdem über eine Subskription nachzudenken (Förderung OS Gedanken, Professionieller Support und Schulung, mehr Features die erst später irgendwann in der freien Version ankommen)
	\subsection{Nagios}
	%TODO: Nagios als Kern, mit wenigen zusätzlichen Funktionen, die Funktionsumfänge die wir in der großen Version sehen werden mit externen Programmen realisiert.
	%TODO: Funktionsweise von Nagios kurz erläutern, aktive & passive Checks, auf Bild 3.1 Bezug nehmen, sollte für eine kurze Erläuterung absolut ausreichend sein.
	\begin{figure}[!h]
	\centering
	\includegraphics[width=1\textwidth]{pics/NagiosMonitoring.eps}
    \caption[Grober Aufbau von Nagios]{Aufbau einer Nagios Appliance (Quelle: \textcite{nagiosaufbau}}
    \label{fig:nagiosaufbau}
	\end{figure}
	\clearpage
	\subsubsection{Historie}
	Die Wurzeln von Nagios gehen zurück ins Jahr 1996 als Ethan Galstad ein MSDOS Programm schreibt, dass die Erreichbarkeit von Novell Netware Servern per \textit{ping} testet. Er verwendete hierbei schon das Konzept, dass er externe Tools (\textit{ping}) nutzt um die Überprüfungen (\glqq Checks\grqq) durchzuführen, dies ist bis heute das Basisarchitekturkonzept von Nagios.
	
	Die Programmierarbeiten am Vorgänger von Nagios begannen im Jahr 1998, als Galstad beschloß in das Geschäft mit Monitoringsystemen einzusteigen. Die verbesserte Applikation lief unter Linux und wurde im Jahr 1999 unter dem Namen NetSaint als OpenSource veröffentlicht. Ethan Galstad nahm an das vielleicht ein Dutzend Menschen an der Anwendung interessiert sein könnten (wie so oft in der IT Geschichte eine Fehleinschätzung). Im gleichen Atemzug wurden die Plugins (Skripte die Ergebnisse generieren und an Nagios zur Auswertung übergeben, siehe spätere Erläuterungen), die bis dahin ein Teil von NetSaint waren in ein separates Projekt (NetSaint Plugins) ausgegliedert.
	
	Im Jahr 2002 musste der Name des Projekts aus markenrechtlichen Gründen geändert werden. Der neue Name \glqq Nagios\grqq\ ist wie viele Namen im Linux/Unix Umfeld ein rekursives Akronym. Ausgeschrieben bedeutet es \glqq Nagios Ain’t Gonna Insist On Sainthood\grqq, es leitet sich aus dem ehemaligen Namen des Projekts her. Im gleichen Atemzug wurde auch die Entwicklung der Plugins in ein neues Projekt mit dem Namen \glqq Nagios Plugins\grqq verlagert.\footcite{nagiosnamefaq}
	
	In 2007 wird die Nagios Enterprises \acrshort{llc} (\acrlong{llc}) durch Ethan Galstad gegründet, diese bietet Consulting und technische Unterstützung rund um Nagios an.
	
	Seit 2009 gibt es Nagios auch als kommerzielle Variante, genannt Nagios XI. Das bisherige Nagios wird in Nagios Core umbenannt.
	\footcite{nagioshistory}. 
	
	2009 wurden auch die Forks (Abspaltungen) Icinga und Shinken aus der Taufe gehoben, beide eine Folge daraus, dass sich die Community im (noch dazu sehr schleppend verlaufenden) Nagios (Core) Entwicklungsprozess nicht ausreichend wiederfand.
	
	Im Jahr erscheint Nagios Core 4
	
	In den folgenden Jahren machte die Nagios Enterprise und ihr Gründer Galstad durch ihren rigide Umgang mit den Rechten am Namen Nagios von sich reden, so änderten beispielsweise die von der Community getragene Seite \url{nagios-portal.de} und  auf Druck von Nagios Enterprises ihre Namen in \url{monitoring-portal.de}\footcite{nagiosportal}  Im Fall der Nagios Plugins (\url{nagios-plugins.org}) die bis dato von der Community entwickelt wurden, ging der Umbenennung in Monitoring Plugins (\url{monitoring-plugins.de})  ein Streit um die Nennung von Nagios Forks auf der Seite des Projekts voraus, der darin gipfelte das die Firma Nagios Enterprises die Domain ohne Rücksprache mit der Community auf eigene Server umleitete, was dann die Namensänderung zur Folge hatte.\footcite{nagiosplugin}.
	
	\subsubsection{Lizenzmodell}
	Der Kern der Nagios Umgebung (Nagios Core) und die Plugins stehen unter der GPLv2, sie dürfen also frei verwendet, verändert und weitergegeben werden.\footcite{gplv2en} Nagios Core an sich kann ohne Lizenzgebühren verwendet werden, für die Enterprise Variante, für manche Addons, Plugins oder fertig gebaute Appliances (fertig aufgebaute Monitoringumgebung meist als Image für eine Virtualisierungsumgebung oder als komplett fertiger Server) können aber durchaus Kosten anfallen.
	\subsubsection{Funktionsumfang}
	Um mit Nagios Core ein funktionsfähiges Monitoring erstellen zu können, sind immer mindestens zwei Komponenten nötig, zum einen Nagios Core, zum anderen die Nagios Plugins, die für die aktive Überwachung notwendigen Skripte.
	Nagios Core selbst besteht aus den folgenden Komponenten\footcite{veltnagios1}:
	\begin{itemize}
		\item Nagios Framework
		\item Verwaltung, Scheduling
		\item Ausführung von Checks (Plugins)
		\item Benachrichtigungen
		\item Entgegennahme von Ereignissen
		\item Web-Frontend zur Übersicht und Administration
	\end{itemize}
	Möchte man weitere Funktionalitäten hinzufügen, \acrlong{bspw} eine grafische Auswertung bestimmter Daten, so muss man auf Addons wie \textit{Nagios2RRD(N2RRD)}\footcite{n2rrdprojecthome} zurückgreifen. Das gleiche gilt für Business Process Intelligence (BPI) um Geschäftsprozesse in der Überwachung abzubilden und deren Status zu überwachen.\footcite{nagiosbpi}. Viele weitere Aufgaben können auch per Addon \glqq nachgerüstet \grqq werden, es empfiehlt sich auf jeden Fall einen Blick auf die verfügbaren Module zu werfen, die Auswahl ist reichhaltig. Der Funktionsumfang kann natürlich auch von jedem Benutzer durch selbstgeschrieben Addons erweitert werden, hier sind den Möglichkeiten keine Grenzen gesetzt.
	
	
	\subsubsection{Konfiguration}
	Die Konfiguration von Nagios basiert im wesentlichen auf einer objektorientierten Struktur. Ein Nagios Objekt beschreibt immer eine bestimmte Einheit, selbst (Check-)Kommandos werden als Objekte definiert. Nagios beherrscht unter anderem die Vererbung von Eigenschaften. Es gibt im wesentlichen folgenden Objekttypen:
	\begin{itemize}	
		\item Host \\
		Beschreibt den zu überwachenden Netzwerkknoten, wesentliche Parameter sind hier IP-Adresse und Name
		\item Hostgroup \\
		Mehrere Hosts lassen sich in einer (logischen) Gruppe zusammenfassen, dies erleichtert später die Konfiguration, da statt einzelner Hosts auch Hostgroups in die Konfiguration geschrieben werden können, auch sorgt eine gruppierte Darstellung für eine bessere Übersichtlichkeit.
		\item Service \\
		Definiert einen Dienst auf einem Host der (aktiv) überwacht oder für den Ereignisse gemeldet werden sollen. Ein Service kann nie unabhängig von einem Host existieren (Host-Service-Paar).
		\item Servicegroup \\
		Wie die Hostgroup dient die Servicegroup dazu, mehrer Services zusammenzufassen. Dies kann später beim Reporting nützlich sein und führt auch wie bei en Hostgroups zu einer gruppierten Darstellung auf der Nagios Oberfläche.
		\item Contact
		Definiert eine Person, zum einen um Sie über bestimmte Ereignisse informieren zu können, zum anderen um eine Art Zugriffskontrolle auf der Nagios Oberfläche zu etablieren (hier werden Hosts \& Services für die der jeweilige Contact nicht zuständig ist ausgeblendet beziehungsweise nicht angezeigt). Auch für Kontakte besteht wieder die Möglichkeit Gruppen (contactgroups) anzulegen.
		\item Timeperiod
		In diesem Objekt können Zeitfenster definiert werden, die dann im Fehlerfall für eine feine Steuerung der Benachrichtigungen dienen können. (Wer wird wann benachrichtigt?)
		\item Command
		Externe Programme werden in Nagios immer als Kommando-Objekte aufgerufen, dies ist der Fall bei allen Plugins, aber auch bei Programmen die Benachrichtigungen (E-Mail, SMS) versenden. 
	\end{itemize}
	Es existieren natürlich noch mehr Objekttypen, die hier genannten sind aber die grundlegenden, auf deren Basis man ein funktionierendes Monitoringsystem aufbauen kann.
	\footcite[Kapitel 2.2]{barthnagios}
	
	\subsubsection{Überwachung}
	Die Überwachung mit Nagios wird durch die sogenannten Nagios Plugins realisiert, standardmäßig sind sehr viele Einsatzfälle von Nagios mit den Standardplugins abgedeckt. Natürlich kann wie bei den Addons auch jeder Nutzer seine eigenen Plugins entwickeln. Dabei ist lediglich zu beachten, das sich die Entwicklung der Plugins, bezüglich Verhalten und Rückgabewerten an die Standards der \glqq Nagios Plugin Development Guidelines\grqq\footcite{nagiospluginguidelines} hält. Diese zielen weniger darauf ab dem Entwickler eine bestimmte Programmiersprache vorzugeben, als mehr darauf ihm mitzugeben welches Verhalten und welche Rückgaben Nagios von einem Plugin erwartet, die Wahl der Programmiersprache bleibt weitestgehend frei. Einige dieser Voraussetzungen sind \acrlong{bspw}, dass ein definierter Statuscode zurückgegeben wird und die Ausgabe auf STDOUT erfolgen muss. Mittlerweilen sind mehrzeilige Rückgaben erlaubt. dies war aber sehr lange Zeit nicht der Fall. Bis zur Version 3 konnte Nagios nur einzeilige Rückgaben verarbeiten.
	
	Wie sieht ein typischer Rückgabewert von einem Nagios Plugin nun aus? \medskip
	
	\begin{lstlisting}[language=bash, caption=Rückgabe eines ICMP Checks, showlines=false, breaklines=true,numberblanklines=false, label=lst:icmpcheck]
		OMD[testsite]:~/lib/nagios/plugins$ ./check_icmp localhost
		
		OK - localhost: rta 0,036ms, lost 0%|rta=0,036ms;200,000;500,000;0; pl=0%;40;80;; rtmax=0,086ms;;;; rtmin=0,022ms;;;; 
		
		OMD[testsite]:~/lib/nagios/plugins$ echo $?
		0	\end{lstlisting}
	Deutlich zu sehen ist hier, dass zuerst ein Status zurückgegeben wird (hier: OK). Es gibt hier insgesamt 4 unterschiedliche Status\footcite[Plugin Return Codes]{nagiospluginguidelines} die hier zurückgegeben werden können:
	\begin{itemize}
		\item OK (Return Code: 0)\\
		wird auf der Oberfläche durch die Farbe grün repräsentiert
		\item Warning (Return Code: 1)\\
		wird auf der Oberfläche durch die Farbe gelb repräsentiert
		\item Critical (Return Code: 2)\\
		wird auf der Oberfläche durch die Farbe rot repräsentiert
		\item Unknown (Return Code: 3)\\
		wird auf der Oberfläche durch die Farbe grau repräsentiert
	\end{itemize}
	Die Status werden in der Überwachung auch farblich aufgegriffen, d.h. nach ihrer Schwere mit den entsprechenden Farben markiert und entsprechend die konfigurierten Benachrichtigungen verschickt, Aktionen ausgeführt. Zu jedem Status gehört natürlich der entsprechende Return Code, siehe oben in der Aufzählung.
	
	Als zweiter Wert wird der überwachte Host angegeben. Danach folgen weitere Werte (hier die Werte die von \textit{ping} üblicherweise zurückgegeben werden) die später grafisch aufbereitet werden können.
	
	Nun haben wir die Basis eines jeden Nagios Systems kennengelernt und können uns nun damit beschäftigen wie Nagios eigentlich überwacht, d.h. wie die Werte in das System kommen und wie die Überwachung ausgelöst wird.
	
	Einfache Basis-Checks wie der oben in \ref{lst:icmpcheck} ausgeführt \textit{check\_icmp} brauchen keinen Zugriff auf den entfernten Server, ihnen reicht es ja völlig aus, wenn der Server per \acrfull{icmp} Paket erreichbar ist. Aber was nun wenn wir Daten direkt vom Server haben wollen, wie zum Beispiel die CPU Auslastung? Hier brauchen wir einen Weg, wie wir die Daten vom zu überwachenden Rechner auf den Überwachungsrechner bekommen. Hierfür gibt es mehrere Möglichkeiten:
	
	\begin{itemize}
		\item \acrfull{snmp}\\
		\acrshort{snmp} ist ein Protokoll, das dazu entwickelt wurde Netzwerkgeräte zu überwachen und zu verwalten. Letzterer Teil ist für uns ohne Belang, wir wollen die Netzwerkgeräte ja im wesentlichen nur überwachen, nicht verwalten. Für Server ist dieser Mechanismus um Werte anzurufen nicht empfehlenswert, da diese über Plugins effizienter abgefragt werden können. Gleichwohl wäre aber eine Überwachung von Servern möglich, es muss nur auf den abzufragenden Rechner ein SNMP-Service(/Daemon) installiert und eingerichtet sein. Bei Netzwerkgeräten (Router, Switche, etc.) ist dies allerdings oftmals die einzige Möglichkeit an Werte zu kommen, hier muss und kann es dann natürlich auch zum Einsatz kommen. Die Nagios Plugins bieten standardmäßig das Plugin \textit{check\_snmp} an um Überwachung per SNMP zu ermöglichen.
		\footcite[Kapitel 11]{barthnagios}
		\item Skriptaufruf per SSH (\textit{check\_by\_ssh}): \\
		Der Nagios Rechner (bzw. das Nagios Plugin \textit{check\_by\_ssh}) triggert die Ausführung des Skripts auf dem entfernten Rechner per ssh und nimmt das Ergebnis entgegen. Vorteil dieses Verfahrens ist auf jeden Fall das die Datenübertragung verschlüsselt stattfindet. Nachteilig ist, dass jeder Check eine eigene SSH Verbindung benötigt, dies verursacht zum einen Netzlast, zum anderen auch Auslastung auf beiden Rechnern (Überwachungsrechner und überwachtem Rechner), für einzelne Checks auf einem Rechner ist dieses Verfahren sicherlich in Ordnung, für viele Rechner und viele zu überwachende Parameter ist das Verfahren nicht geeignet.
		\item \acrfull{nrpe}: \\
		\acrshort{nrpe} besteht aus zwei Teilen, einem Daemon für den zu überwachenden Rechner und einem Plugin für den Nagios Server, das die Ergebnisse abholt (siehe auch Abbildung \ref{fig:nrpe}). Der Daemon führt ausgelöst durch das Plugin (\textit{check\_nrpe} auf dem Überwachungsrechner) die auf dem zu überwachendem Rechner konfigurierten Plugins aus (in der Abbildung beispielhaft, Checks für die Festplattenauslastung und für die Load Werte) und meldet die Rückgabewerte an Nagios. Hierdurch wird die Last auf Netz und Rechner gegenüber \textit{check\_by\_ssh} um einiges verringert, eine verschlüsselte Übertragung ist natürlich ebenfalls möglich.
		\begin{figure}[h!]
			\centering
			\includegraphics[width=1\linewidth]{pics/nrpe}
			\caption[Funktionsweise NRPE]{Die Funktionsweise von \acrlong{nrpe} (Quelle: \cite{nagioscoreaddons})}
			\label{fig:nrpe}
		\end{figure}
	\end{itemize}
	
	Die abgefragten Werte werden von der Oberfläche nun grafisch aufbereitet und entsprechende Aktionen ausgeführt. 
	
	Woher weiß das Plugin welchen Status es zurückgeben muss? Dies wird über Schwellwerte beim Aufruf bestimmt, es gibt einen Schwellwert für Critical (\textit{-c}) und einen für Warning (\textit{-w}). Einen Check Aufruf mit Warning und Critical Schwellwerten sieht man in Listing \ref{lst:checkdisk}, wobei die Werte hier absichtlich so gewählt wurden, dass ein anderes Ergebnis als DISK OK zurückkommt, realistische Einstellungen wären, 20\% für Warning und 10\% für Critical.
	
	\begin{lstlisting}[language=bash, caption=Rückgabe von \textit{check\_disk} mit Parametern, showlines=false, breaklines=true,numberblanklines=false, label=lst:checkdisk]
	df -h | grep /dev/sda1
	/dev/sda1       8,2G    3,9G  3,9G   51% /
	
	./check_disk -w 50% -c 20% -p /dev/sda1
	
	DISK WARNING - free space: / 3906 MB (49% inode=68%);| /=3967MB;4159;6655;0;8319 \end{lstlisting}
%TODO Notification?
	
	
	Als Fazit aus der (kurzen) Betrachtung der Funktionsweise von Nagios lässt sich schließen, das Nagios ein mächtiges Tool zur Netzwerküberwachung ist, aber sein der größter Vorteil, auch der größte Nachteil ist, durch die modulare Erweiterbarkeit und die extreme Vielfalt braucht es auch erstmal einiger Einarbeitung um ein wirklich funktionierendes Monitoring konfiguriert zu bekommen. Das alle benötigten Daten von den Systemen bekommt und diese aufbereitet.
	
	\subsection{Die \acrlong{omd} - nur ein besser konfigurierbares Nagios?}
	\subsubsection{Historie}
	Um den Nachteil der komplexen Konfiguration von Nagios zu umgehen haben sich im Jahr 2010 einige Nagios Entwickler zusammengetan und mit \acrfull{omd}, eine vorkonfigurierte Nagios-Installation mit einigen Addons ins Leben gerufen. Die Entwickler von OMD sind in der Nagios-Szene allesamt keine unbekannten und entwickeln seit Jahren an Projekten wie der Visualisierung Nagvis (Lars Michelsen), der Agentensoftware Check\_mk (Mathias Kettner), dem Performance-Analysetool Pnp4nagios (Jörg Linge) oder dem Webinterface Thruk (Sven Nierlein) bekannt beziehungsweise schreiben zwei der Standardwerke zum Thema \glqq Nagios\grqq (Wolfgang Barth, Gerhard Laußer) \footcite{omdhistory}. In der Folge entwickelte sich um die \acrshort{omd} eine sehr aktive Community. Die eigentliche \acrlong{omd} macht auf den ersten Blick nicht den Eindruck einer stark weiterentwickelten Version, es ist seit  aber die Entwicklungsversionen sprechen eine andere Sprache, darüber hinaus vertreiben einige der Autoren \glqq ihre\grqq Software als angepasstes \acrshort{omd}, beispielsweise Mathias Kettner mit Check\_MK und Sven Nierlein mit der OMD Labs Edition\footnote{https://labs.consol.de/de/}.
	\subsubsection{Lizenzmodell}
	Die OMD und ihre Derivate (Check\_MK Raw Edition und OMD Labs Edition) stehen wie Nagios unter der GPLv2\footcite{checkmkcre}. Von Mathias Kettner gibt es eine kostenpflichtige Enterprise Edition, die dann einige Features mehr hat und einen professionellen Support bietet.
	\subsubsection{Funktionsumfang}
	Wir werden uns in der Folge mit der Check\_MK-Variante der \acrshort{omd} beschäftigen, diese hat als Besonderheit und wesentliche Arbeitserleichterung den speziellen Check Mechanismus von Mathias Kettner im Angebot, doch dazu später mehr. Erstmal werden wir uns kurz mit dem Aufbau des Systems beschäftigen, das Schaubild \ref{fig:checkmk} gibt einen groben Überblick über die wesentlichen Komponenten des Systems, deutlich zu sehen, anders als Nagios im letzten Kapitel ist man mit diesem System ohne große Umschweife bereit, auch Visualisierungen von Performancedaten zu erstellen. Die benötigten Addons \textit{NagVis} \& \textit{PNP4Nagios} sind bereits installiert und konfiguriert, sobald (visualierbare) Daten vorliegen werden diese auch visualisiert. Die OMD genannte Komponente übernimmt das Management der Software (Stichwort: automatisches Update), die Verwaltung der Sites (es ist möglich auf einem Rechner mehrere Sites genannte, komplett voneinander getrennte Monitoringsysteme zu betreiben, sogar mit unterschiedlichen Versionen von OMD\footcite{omdhomepage}) und OMD könnte auch ein geclustertes Monitoring verwalten (also ein Monitoring verteilt auf mehrere Server).
	\begin{figure}
		\centering
		\includegraphics[width=1\textwidth]{pics/checkMKAufbau.eps}
		\caption[Komponenten des Check\_MK Monitoring Systems]{Komponenten des Check\_MK Monitoring Systems (Quelle: \cite{checkmkmonitoringpic})}
		\label{fig:checkmk}
	\end{figure}
	Die größte Besonderheit, ist aber das Check\_MK, wie in Abbildung \ref{fig:checkmkaufbau} zu sehen, erweitert es die Überwachung von Servern um eine zusätzliche Komponente. Diese löst die Nagios Plugins als Standard für die Überwachung ab und integriert ein eigenes Tool mit dem Namen Check\_MK, das aber noch sehr viel mehr kann, als nur zu überwachen, es bringt auch eine neue Weboberfläche mit, mittels derer die komplette Konfiguration erledigt werden kann, es ist also für einen Start und die Erstellung eines einfachen Monitorings nicht mehr notwendig sich ausführlich mit dem System auseinanderzusetzen. Doch zurück zur Überwachung, anstelle von NRPE tritt bei Check\_MK der sogenannte \acrlong{cmk} Agent, dieser ist für viele Plattformen bereits paketiert erhältlich und muss nur installiert und gestartet werden. Danach kann der Host über die Weboberfläche eingerichtet werden (Name und IP reichen aus), \acrlong{cmk} übernimmt danach die weitere Einrichtung des Monitorings automatisch, es inventarisiert die auf dem Host vorhandenen Services und beginnt mit dem Monitoring, nur bei wenigen Services ist ein manuelles Konfigurieren notwendig (beispielsweise Datenbanken oder Applicationserver). Das macht es einfacher eine grundlegende Überwachung mit Bereichen aus der \glqq erweiterten Überwachung\grqq\ einzurichten und danach sich langsam vorzutasten (z.B. in den Bereich der Datenbanküberwachung). Einen Nachteil hat der Agent, allerdings er kann die Daten per default nicht verschlüsselt verschicken, dies kann aber mit einem Trick (Aufruf des Agenten per ssh) umgangen werden, dazu kommen wir noch im praktischen Teil in Kapitel 4.
	\begin{figure}
		\centering
		\includegraphics[width=1\textwidth]{pics/OMD_Schema.eps}
		\caption[Aufbau von Check\_MK]{Aufbau von Check\_MK (Quelle: \cite{checkmk})}
		\label{fig:checkmkaufbau}
	\end{figure}
	\clearpage
	\section{Fazit}
	Für den Bereich des Performance und SLA Monitorings bietet Nagios auf jeden Fall die optimale Ausgangsposition. Wenn man sich nicht ausführlich mit der Einrichtung und Konfiguration beschäftigen will, bietet sich eine Lösung wie OMD (respektive Check\_MK an). Diese bietet out-of-the-box einen großen Funktionsumfang, für den man sich mit Nagios schon einige Zeit intensiv beschäftigen müsste. Wenn man OMD im professionellen Einsatz hat, empfiehlt es sich eventuell einen Blick auf die kostenpflichtige Variante zu werfen und abzuwägen ob Support und zusätzliche Features die Kosten rechtfertigen.
	\section{Logfile Monitoring}
	Wie im ersten Teil bereits erwähnt gehört zu einem voll umfänglichen Monitoring System auch eines, dass in der Lage ist die unterschiedlichen Logfiles aus unterschiedlichen Quellen (systemd, syslog-ng, rsyslog) zu bündeln, zentral zu speichern, auszuwerten und beim Auftreten verschiedener Muster Alarm zu schlagen.
	
	Nach einer kurzen Marktanalyse ergeben sich unter anderem folgende Tools:
	\begin{itemize}
		\item Syslog-NG
		\item Splunk
		\item Nagios Log-Server
		\item \acrlong{elk}
	\end{itemize}
	Von der Funktionsweise sind alle Anwendungen vergleichbar, sie können Logfiles aus verschiedenen Quellen annehmen, sie speichern und auswerten. Unterschiede tun sich die preisliche Gestaltung und erweiterte Features wie beispielsweise eine grafisch Oberfläche auf. So sind Splunk und der Nagios Log-Server nur gegen Gebühren erhältlich und fallen deshalb aus der Auswahl. Syslog-NG war der erste Gedanke, weil in der Vorlesung gelernt, erfüllt auch alle Anforderungen, bietet aber keine grafische Oberfläche. Die Wahl fällt auf den \acrshort{elk} Stack der in der Folge näher betrachtet werden, inkl. seiner Integration in ein Monitoring System.
	%TODO mehr begründen?
	
	\subsection{Elasticsearch - Logstash - Kibana}
	Oftmals auch \acrshort{elk} oder ELK-Stack genannt sind eigentlich die drei voneinander unabhängige Tools \acrlong{elk}.Um die Funktionsweise und die Integration in unser Monitoring besser erklären zu können, werden die einzelnen Tools mit ihren Möglichkeiten in den folgenden Unterkapiteln kurz vorgestellt und im Anschluß daran ihr Zusammenspiel untereinander und mit dem Monitoring erläutert.
	\subsubsection{Elasticsearch}
	Elasticsearch ist eine in Java implementierte, auf Apache Lucene basierende Suchmaschine. Derzeit ist Elasticsearch die am weitesten verbreitete Suchmaschine\footcite{dbenginesranking}. Sie dient im Stack dazu die von Logstash eingesammelten Logfiles zu indexieren. Lizensiert werden kann Elasticsearch wie auch Logstash und Kibana unter der Apache Lizenz\footcite{apachelicence}.\footcite{elasticsearch}
	\subsubsection{Logstash}
	Logstash dient der Verarbeitung und Normalisierung von Logdateien. Im \acrshort{elk}-Stack werden über sogenannte Input-Module die Datenquellen (siehe auch Abbildung \ref{fig:elk}) eingelesen, dies können beispielsweise Datenströme von Syslog sein oder Protokolldateien beispielsweise von selbstgeschriebener Software. Auch bietet Logstash die Möglichkeit mittels des Tools Filebeat auf entfernten Servern Protokolle zu sammeln und gesammelt und verschlüsselt an den Server zu übertragen.\footcite{filebeat} Danach können mittels Filter-Plugins die Daten je nach Konfiguration durch den Benutzer weiterbearbeitet werden, dieser Schritt kann allerdings auch entfallen. Nach erfolgter oder auch nicht erfolgter (wenn die Filter ausgelassen werden) Filterung werden die Ergebnisse an Elasticsearch zum Indizieren weitergegeben werden. \footcite{logstash}
	\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{pics/logstashcheckmk}
	\caption{Integration von Logstash in Check\_MK}
	\label{fig:logstashcheckmk}
	\end{figure}
	Um die Daten in unser Nagios/Check\_MK Monitoring zu bekommen, brauchen wir ebenfalls Logstash, dieser liefert wie in Abbildung \ref{fig:logstashcheckmk} zu sehen, die nach bestimmten Mustern gefilterten Daten mit dem entsprechend zu setzenden Status weiter an unser Monitoringsystem wo diese weiterverarbeitet werden. Und der entsprechend Zuständige dann benachrichtigt wird.
	\subsubsection{Kibana}
	Kibana kann mit dem Elasticsearch \acrshort{rest} \acrshort{api}s umgehen und ergänzt den Stack um eine Komponente zur grafischen Ausgabe, mit Kibana können die Logdaten in Echtzeit aufbereitet werden.\footcite{kibana}\footcite{elk2015}
	\begin{figure}[h!]
		\centering
		\includegraphics[width=1\textwidth]{pics/elk-stack.eps}
		\caption[Aufbau eines Elasticsearch - Logstash - Kibana Stacks]{Aufbau eines Elasticsearch - Logstash - Kibana Stacks (Quelle: \textcite{elkstackpic})}
		\label{fig:elk}
	\end{figure}
	\clearpage
	
	%TODO Netways Präsentation für Integration in Nagios
	\chapter{Praktische Vorstellung der Funktionalität eines Monitoring Systems}
	\section{Grundlegende Überlegungen}
	Um kurz noch einen praktischen Einblick in die verwendete Software zu geben wird sich der folgende Teil mit dem praktischen Aufbau einer kleinen \glqq Spielwiese\grqq\ beschäftigen. 
	
	Es wird auf Basis eines kleinen Versuchsaufbaus, der komplette Prozess (wie in Kapitel 3 beschrieben) bis zu einem fertigen Monitoring durchlaufen.
	\subsection{Versuchsaufbau}
	Im wesentlichen besteht dieser Aufbau aus zwei virtuellen Maschinen die mittels VirtualBox realisiert wurden und einem entfernten Server der bei einem Hoster in einem Rechenzentrum steht. Mit den beiden virtuellen Maschinen werden Server in einem Rechenzentrum simuliert, diese stehen in einem nach außen abgeschotteten Netz, die Datenübertragung bedarf deshalb keiner besonderer Sicherheitsvorkehrungen, der entfernte Server ist nur übers Internet erreichbar (potentiell unsicher!) und die Übertragung der Daten bedarf deshalb einer Verschlüsselung.
	\subsection{Was soll überwacht werden?}
	Wir wollen Performancedaten \& Verfügbarkeit der Systeme überwachen, realisieren also grundlegende und erweiterte Überwachung. Was wir in diesem kurzen Beispiel nicht überwachen sind die Logfiles.
	\subsection{Wie kann überwacht werden?}
	Im wesentlichen werden wir uns bei der Überwachung auf die Daten aus dem Check\_MK Agenten verlassen, dieser betreibt aktive Überwachung.
	Die Log Dateien sollten eigentlich beim Auftreten bestimmter Patterns in die Überwachung übertragen werden (passive Überwachung).
	\subsection{Wer soll im Fehlerfall benachrichtigt werden?}
	Im Fehlerfall sollte natürlich der Administrator benachrichtigt werden, ggf. unterteilt in verschiedene zuständige Teams.
	\subsection{Welche \acrlong{sla}s existieren bereits?}
	Der Einfachheit halber existiert für unsere Teststellung nur ein SLA, nämlich zur Verfügbarkeit unserer Website.
	\subsection{Welche Software ist für meine Zwecke am besten geeignet?}
	Wir folgen dem Fazit aus Kapitel 3 und setzen Check\_MK in der RAW Edition ein. Für unsere Zwecke ist die RAW Edition völlig ausreichend.
	\section{Grundlegende Beschreibung der verwendeten Systeme}
	\subsection{verwendete Software}
	Als Betriebssystem auf dem Überwachungsrechner (im weiteren Verlauf \glqq Überwachungsrechner\grqq\ genannt) kommt Debian 8.2 zum Einsatz, dies hat den Grund, das Check\_MK in Verbindung mit SuSE beim Aufbau einige Probleme mit fehlenden Paketen hatte, diese Pakete werden mittlerweilen auf der Seite von Check\_MK zum Download angeboten, zu Beginn der Arbeiten war dies allerdings nicht der Fall.
	
	Der entfernte Rechner ist ein virtueller Server (im folgenden \glqq Webserver\grqq\ genannt) bei einem großen Hoster, als Betriebssystem läuft auf diesem Rechner Opensuse 13.2 (64bit) mit der für Webserver üblichen Software (LAMP-Stack = Linux Apache Mysql PHP) und zusätzliche zwei Java Anwendungen (Jenkins \& Sonarqube) mit ihren eigenen Applicationservern. An zusätzlicher überwachter Sicherheitssoftware ist Fail2Ban\footcite{fail2ban} installiert, bei Fail2Ban handelt es sich um eine Sicherheitssoftware, die das Systemlog (\path{/var/log/messages}) auf bestimmte Muster durchsucht, dies dient der Abwehr von Angriffen gegen den Rechner. Am Beispiel von SSH kurz erläutert: Versucht die gleich IP sich mehrmals vergeblich per SSH mit dem Server zu verbinden wird diese nach drei Versuchen für eine bestimmte Zeit gesperrt über eine Firewallregel gesperrt.
	
	Als dritter Rechner kommt eine virtuelle Maschine (im folgenden \glqq virtuelle Maschine\grqq) auf dem gleichen Träger zum Einsatz, diese war für die Entwicklung eines Softwareprojekts für ein anderes Studienfach im Einsatz. Neben den allgemeinen Systemparametern wird auf diesem Rechner noch eine MySQL Datenbank überwacht.
	\subsection{Installation}
	Zuerst muss auf dem Überwachungsrechner die benötigte Software installiert werden. Leider gibt es für Check\_MK\footcite{checkmk} kein Repository weshalb das Paket immer händisch aktualisiert werden muss.
    Anschließend muss die Software mitsamt ihren Abhängigkeiten installiert werden, dies wird in zwei Schritten realisiert, zuerst wird das Paket mit \textit{dpkg} zur Installation vorgemerkt (Listing \ref{lst:installomd}, Zeile 1), danach wird das Paket mittels des Kommandos \textit{apt-get} mit allen notwendigen Abhängigkeiten installiert (Zeile 2). Nach dem Abschluß der Paketinstallationen muss noch eine Site (also ein Monitoringsystem) angelegt und gestartet werden. Danach ist der Überwachungsrechner einsatzbereit und über die Weboberfläche erreich- und konfigurierbar. \medskip
	\begin{lstlisting}[language=bash, caption=Installation von Check\_MK, label=lst:installomd]	
	dpkg -i check-mk-raw-1.2.6p15-sles12-34.x86_64.deb
	apt-get -f install
	omd init testsite 
	omd start testsite\end{lstlisting}
	Als nächster Schritt müssen die virtuelle Maschine und der Webserver mit den Überwachungsagenten bestückt werden (siehe Listing \ref{lst:installomdagent}). Hierbei ist zu beachten, dass auf dem Rechner der \textit{xinetd} installiert und aktiviert sein muss, damit der Check\_MK Agent funktioniert. Nach der Installation der Agenten haben wir den Installationsteil abgearbeitet und gehen jetzt über zur Konfiguration.
	\begin{lstlisting}[language=bash, caption=Installation des Check\_MK Agenten, label=lst:installomdagent]
	rpm -ihv check-mk-agent-1.2.6p15-1.noarch.rpm\end{lstlisting}
	\subsection{Konfiguration}
	Die Konfiguration des Monitorings besteht im wesentlichen daraus, die Server mit dem Monitoring bekannt zu machen und eine Inventarisierung anzustoßen. Dies kann bequem über die Oberfläche passieren (siehe Abbildung \ref{fig:hostreg} und \ref{fig:hostservices}). Nach Abschluss der Inventarisierung, müssen die gewünschten Überwachungswerte noch ausgewählt und aktiviert werden. Danach ist die grundlegende Arbeit getan und der Server wird überwacht (siehe Abbildung \ref{fig:monitoring}).
	\begin{figure}[h!]
		\centering
		\includegraphics[width=1\textwidth]{pics/hostReg.eps}
		\caption[Registrierung eines Hosts]{Registrierung eines Hosts in Check\_MK}
		\label{fig:hostreg}
	\end{figure}
	\begin{figure}[h!]
		\centering
		\includegraphics[width=1\textwidth]{pics/hostReg.eps}
		\caption[Auf dem Host verfügbare Services]{Auf dem Host nach der Inventarisierung verfügbare Services}
		\label{fig:hostservices}
	\end{figure}
	\begin{figure}[h!]
		\centering
		\includegraphics[width=1\textwidth]{pics/hostReg.eps}
		\caption[Die Überwachungsseite für den neu angelegten Host]{Die Überwachungsseite für den neu angelegten Host}
		\label{fig:monitoring}
	\end{figure}
	\section{Performancemonitoring}
	\subsection{Überwachung eines entfernten Servers}
	Der Check\_MK Agent hat ziemliche viele der Dienste die wir überwachen wollen schon per default erkannt und in die Überwachung eingefügt. Die Erreichbarkeit des Servers, die Auslastung der CPU, die Belegung des Arbeitsspeichers und der Festplatten, der Status des NTP Daemons alles bereits eingerichtet und überwacht. Was uns jetzt noch fehlt ist eine Überwachung des Apache Webservers und der MySQL Datenbank und weil der Webserver ja nur über das Internet erreichbar ist, wollen wir das der Check\_MK Agent via SSH abgefragt wird. Hierfür müssen wir zwei Schritte ausführen, zum einen muss ein Schlüsseltausch durchgeführt werden, sodass der Überwachungsrechner sich ohne Passwort am Webserver anmelden kann. Dies kann im wesentlichen durch zwei Schritte erreicht werden. 
	\begin{enumerate}
		\item SSH Schlüssel vom Überwachungsrechner in die \path{.ssh/authorized\_keys} des Webservers eintragen.
		\item Schlüssel auf die Ausführung eines Kommandos begrenzen, aus Sicherheitsgründen. Dies wird erreicht durch
		\begin{lstlisting}[language=bash, caption=SSH Schlüssel auf ein Kommando begrenzen, label=lst:keybegr]
		command="sudo /usr/bin/check_mk_agent"\end{lstlisting}
		vor dem eigentlichen Schlüssel. Zusätzlich ist auf diesem Server noch eingerichtet, dass der check\_mk\_agent über \textit{sudo} als Superuser ausgeführt wird, sodass der SSH Login mit Schlüssel über einen unpriviligierten Benutzer (obwohl der Check\_MK Agent Root Rechte braucht) geschehen kann.\footcite{checkmkCheckBySSH2015}
	\end{enumerate}
	\subsection{Überwachung einer Datenbank und des Apache Webservers}
	Der letzte Schritt zur für unsere Zwecke ausreichenden Überwachung ist die Einrichtung von zwei weiteren Agenten um auch noch die Datenbank und den Apache Webserver überwachen zu können. Hierfür müssen die beiden Agenten \textit{mk\_mysql} und \textit{apache\_status} von der Übersichtsseite des Überwachungsrechners heruntergeladen und auf dem Webserver ins Verzeichnis \path{/usr/lib/check_mk_agent/plugins} kopiert werden. Der Apache Webserver kann danach sofort überwacht werden, es muss nur über die Weboberfläche noch eine erneute Inventarisierung des Servers gestartet werden. Für die Überwachung der MySQL Datenbank ist noch ein Benutzer auf der Datenbank von Nöten. Dieser wird mit dem Befehl
	\begin{lstlisting}[language=sql, caption=Benutzer fürs Monitoring auf der Datenbank anlegen, label=lst:sqluser]
	GRANT SELECT, SHOW DATABASES ON *.*
	TO 'monitoring'@'localhost' identified by 'PASSWORD' ;\end{lstlisting}
	angelegt. Um dem Agenten diese Information zugänglich zu machen muss noch eine Konfigurationsdatei \path{/etc/check_mk/mysql.cfg} mit dem folgenden Inhalt angelegt werden:
	\begin{lstlisting}[language=bash, caption=/etc/check\_mk/mysql.cfg, label=lst:configmkmysql]
	[client]
	user=monitoring
	password=PASSWORD\end{lstlisting}
	Nach einer abschließenden Neuinventarisierung kann jetzt auch die Datenbank überwacht werden (siehe Abbildung \ref{fig:mysqlueberw} ).\footcite{checkmkmysql}
	\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{pics/mysqlueberw}
	\caption[Die MySQL Datenbank in der Überwachung]{Die MySQL Datenbank in der Überwachung}
	\label{fig:mysqlueberw}
	\end{figure}
	\section{Service Level Agreement Monitoring}
	Wie in unserer anfänglichen Beschreibung festgelegt, beschränken wir uns beim \acrshort{sla} Monitoring auf einen absoluten Basisfall, in der Praxis wird das \acrshort{sla}-Monitoring um einiges komplexer ausfallen. Wir richten über die Oberfläche einen (aktiven) Check ein, der auf eine bestimmte URL einen Check ausführt und den Wert Critical bekommt, sobald die Webseite nicht mehr erreichbar ist. Dieser Check kann über die eingebaute Reporting Funktion von Check\_MK ausgewertet und für einen bestimmten Zeitraum ein Verfügbarkeitsreporting erstellt werden. Beispielhaft in \ref{fig:availability} dargestellt, auf einem echten System würde die Grafik ein wenig anders aussehen und die Verfügbarkeit läge wohl näher an 100\%.
	\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{pics/http_check}
	\caption[Überwachung einer Webseite]{Überwachung einer Webseite}
	\label{fig:http_check}
	\end{figure}
	\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{pics/availability}
	\caption[Beispielhafte Darstellung der Verfügbarkeit]{Beispielhafte Darstellung der Verfügbarkeit}
	\label{fig:availability}
	\end{figure}


	
	
	% Abkürzungsverzeichnis auf einer neuen Seite ausgeben
	%\printnomenclature
	% Literaturverzeichnis ausgeben und als Eintrag gleichwertig mit einem Kapitel ins Inhaltsverzeichnis eintragen
	%\begingroup
	%\nocite{*} %Alle Einträge des Literaturverzeichnisses auch ohne Zitierung ausgeben
	%\addcontentsline{toc}{chapter}{Literatur}
	\printbibliography 
	%\addchaptertocentry{}{Literatur}
	%\addcontentsline{toc}{chapter}{Literatur}
	%\endgroup
	\printglossary[title=Abkürzungsverzeichnis, type=\acronymtype] % prints just the list of acronyms	
	%\printglossary[title=Glossar]
	%\printglossaries	
	\listoffigures % Abbildungsverzeichnis
	%\addchaptertocentry{}{Abbildungsverzeichnis}
	%\listoftables % Verzeichnis der Tabellen
	%\addchaptertocentry{}{Tabellenverzeichnis}
\end{document}